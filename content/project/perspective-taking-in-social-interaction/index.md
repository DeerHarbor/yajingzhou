---
title: Perspective-taking in social interaction
date: 2022-09-04T15:40:57.871Z
draft: false
featured: false
authors:
  - admin
image:
  filename: featured.jpg
  focal_point: Smart
  preview_only: false
---
Previous studies have shown that Visual Perspective-taking (VPT) can be subdivided into two levels. Level-1 VPT marks the ability to deduce *what* another person can or cannot see and Level-2 VPT marks the ability to know *how* another person sees an object. However, whether Visual Perspective-taking occurs similarly in Chinese than European participants and the relationship between Level-1 VPT and Level-2 VPT are unclear. This study replicates a study by [Ward et al. (2019, 2020)](#Ward2020) with a Chinese sample and additionally tests whether VPT-2 depends on VPT-1 processing. Participants were required to recognize the version (normal or mirror-inverted) of Chinese characters in different orientations. In some scenes, an avatar (female, male, lamp) would appear on the left or the right of the participant, and I measured perspective taking in terms of whether participants could judge the letters more quickly the more they appeared upright to this avatar. A crucial manipulation is that I added barriers between an agent and letters in some trials, so that they could not see the letter. Results showed that the recognition time was indeed faster when letters were oriented towards (compared to away) the human (but not lamp) avatars, replicating the VPT effect of Ward et al (2019, 2020). However, the barriers did not significantly affect this difference. Therefore, the data suggests that people can spontaneously acquire another personâ€™s visual information in Chinese samples, this visual perspective-taking is driven by human beings rather than inanimate objects, and that Level-1 VPT and Level-2 VPT are independent.